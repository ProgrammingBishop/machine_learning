{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ames Housing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default Libraries\n",
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sns\n",
    "\n",
    "# Model Selection\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "from sklearn.preprocessing   import RobustScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics         import mean_squared_error\n",
    "from scipy.special           import boxcox1p\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.pipeline        import make_pipeline\n",
    "from xgboost                 import XGBRegressor\n",
    "from sklearn.ensemble        import GradientBoostingRegressor\n",
    "from sklearn.linear_model    import Lasso, ElasticNet\n",
    "from sklearn.kernel_ridge    import KernelRidge\n",
    "from mlxtend.regressor       import StackingCVRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option( 'display.max_columns', None )\n",
    "sns.set( rc = { 'figure.figsize' : ( 10, 5 ) } )\n",
    "warnings.filterwarnings( 'ignore' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical_features( df ):\n",
    "    return df.select_dtypes( include = [ 'int64', 'float64' ] ).columns\n",
    "\n",
    "def get_categorical_features( df ):\n",
    "    return df.select_dtypes( include = [ 'object' ] ).columns\n",
    "\n",
    "def return_features_with_null( df ):\n",
    "    still_missing = pd.DataFrame( len( df[ get_categorical_features ] ) - df[ get_categorical_features ].count() )\n",
    "    return pd.DataFrame( still_missing[ still_missing[ 0 ] > 0 ] )\n",
    "\n",
    "def return_rows_with_null( df ):\n",
    "    null_columns = df.columns[ df.isnull().any() ]\n",
    "    print( pd.DataFrame( df[ df.isnull().any( axis = 1 ) ][ null_columns ].head( 10 ) ) )\n",
    "\n",
    "def na_heatmap( df ):\n",
    "    df      = df[ sorted( df.columns ) ]\n",
    "    fig, ax = plt.subplots( figsize = ( 25, 5 ) )\n",
    "    sns.heatmap( df.isnull(), yticklabels = False, cbar = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.getcwd() + '\\\\..\\\\..\\\\..\\\\data\\\\ames_housing\\\\'\n",
    "train_raw = pd.read_csv( data_path + 'train.csv' )\n",
    "test_raw  = pd.read_csv( data_path + 'test.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1460, 81) \n",
      "Test: (1459, 80)\n"
     ]
    }
   ],
   "source": [
    "print( \"Train: {} \\nTest: {}\".format( train_raw.shape, test_raw.shape ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facet_grid = pd.melt( train_raw, value_vars = sorted( get_numerical_features( train_raw ) ) )\n",
    "# grid_plot  = sns.FacetGrid( facet_grid, col = 'variable', col_wrap = 10, sharex = False, sharey = False)\n",
    "# grid_plot.map( sns.distplot, 'value' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facet_grid = pd.melt( train_raw, value_vars = sorted( get_categorical_features( train_raw ) ) )\n",
    "# grid_plot  = sns.FacetGrid( facet_grid, col = 'variable', col_wrap = 10, sharex = False, sharey = False )\n",
    "# grid_plot  = grid_plot.map( sns.countplot, 'value' )\n",
    "\n",
    "# plt.xticks( rotation = 'vertical' )\n",
    "# [ plt.setp( ax.get_xticklabels(), rotation = 60 ) for ax in grid_plot.axes.flat ]\n",
    "# grid_plot.fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplots( figsize = ( 15, 15 ) )\n",
    "# sns.heatmap( train_raw.corr(), vmax = 1, square = True, cmap = 'magma', linecolor = 'white', linewidth = 0.1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Correct Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.scatterplot( x = 'GrLivArea', y = 'SalePrice', data = train_raw )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = train_raw.drop( train_raw[ ( train_raw[ 'GrLivArea' ] > 4000 ) & ( train_raw[ 'SalePrice' ] < 250000 ) ].index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_raw.drop( [ 'SalePrice', 'Id' ], axis = 1 )\n",
    "train_y = train_raw[ 'SalePrice' ]\n",
    "test_X  = test_raw.drop( [ 'Id' ], axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Transform Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot( train_y, bins = 75 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skew: 1.8813 \n",
      "Kurtosis: 6.5231\n"
     ]
    }
   ],
   "source": [
    "print( 'Skew: {} \\nKurtosis: {}'.format( round( train_y.skew(), 4 ), \n",
    "                                         round( train_y.kurtosis(), 4 ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.log1p( train_y )\n",
    "# sns.distplot( train_y, bins = 75 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skew: 0.1216 \n",
      "Kurtosis: 0.8048\n"
     ]
    }
   ],
   "source": [
    "print( 'Skew: {} \\nKurtosis: {}'.format( round( train_y.skew(), 4 ), \n",
    "                                         round( train_y.kurtosis(), 4 ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2917, 79)\n"
     ]
    }
   ],
   "source": [
    "full_X    = pd.concat( [train_X, test_X] )\n",
    "train_end = len( train_X )\n",
    "test_end  = len( full_X )\n",
    "\n",
    "print( full_X.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# na_heatmap( full_X )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Replace Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# na_heatmap( full_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_with_none = [ 'Alley', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'BsmtQual', 'Fence', 'FireplaceQu', \n",
    "                   'GarageCond', 'GarageFinish', 'GarageQual', 'GarageType', 'MasVnrType', 'MiscFeature', 'MSSubClass', 'PoolQC' ]\n",
    "\n",
    "fill_with_zero = [ 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtFullBath', 'BsmtHalfBath', 'BsmtUnfSF', 'GarageArea', 'GarageCars', 'TotalBsmtSF', 'GarageYrBlt', 'MasVnrArea' ]\n",
    "\n",
    "full_X[ fill_with_none ] = full_X[ fill_with_none ].fillna( 'None' )\n",
    "full_X[ fill_with_zero ] = full_X[ fill_with_zero ].fillna( 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Drop Useless Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9989715461090161"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( full_X[ full_X[ 'Utilities' ] == 'AllPub' ] ) / len( full_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X = full_X.drop( [ 'Utilities' ], axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Impute Remaining NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle says NA is Typ\n",
    "full_X[ 'Functional' ] = full_X[\"Functional\"].fillna( 'Typ' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_with_mode           = [ 'Electrical', 'KitchenQual', 'Exterior1st', 'Exterior2nd', 'SaleType', 'MSZoning' ]\n",
    "full_X[ missing_with_mode ] = full_X[ missing_with_mode ].fillna( full_X.mode().iloc[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X[ 'LotFrontage' ] = full_X.groupby( 'Neighborhood' )[ 'LotFrontage' ].transform( lambda x: x.fillna( x.median() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return_features_with_null( full_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return_rows_with_null( full_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X[ 'MSSubClass' ]  = full_X['MSSubClass'].apply(str)\n",
    "full_X[ 'OverallCond' ] = full_X['OverallCond'].astype(str)\n",
    "full_X[ 'YrSold' ]      = full_X['YrSold'].astype(str)\n",
    "full_X[ 'MoSold' ]      = full_X['MoSold'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create Ranked Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X[ 'Alley'        ].replace( { 'None' : 0, 'Grvl' : 1, 'Pave' : 2 }, inplace = True )\n",
    "full_X[ 'BsmtCond'     ].replace( { 'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4 }, inplace = True )\n",
    "full_X[ 'BsmtExposure' ].replace( { 'None' : 0, 'No' : 1, 'Mn' : 2, 'Av' : 3, 'Gd' : 4 }, inplace = True )\n",
    "full_X[ 'BsmtFinType1' ].replace( { 'None' : 0, 'Unf' : 1, 'LwQ' : 2, 'Rec' : 3, 'BLQ' : 4, 'ALQ' : 5, 'GLQ' : 6 }, inplace = True )\n",
    "full_X[ 'BsmtFinType2' ].replace( { 'None' : 0, 'Unf' : 1, 'LwQ' : 2, 'Rec' : 3, 'BLQ' : 4, 'ALQ' : 5, 'GLQ' : 6 }, inplace = True )\n",
    "full_X[ 'BsmtQual'     ].replace( { 'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "full_X[ 'ExterCond'    ].replace( { 'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "full_X[ 'ExterQual'    ].replace( { 'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "full_X[ 'Fence'        ].replace( { 'None' : 0, 'MnWw' : 1, 'GdWo' : 2, 'MnPrv' : 3, 'GdPrv' : 4 }, inplace = True )\n",
    "full_X[ 'FireplaceQu'  ].replace( { 'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "full_X[ 'Functional'   ].replace( { 'None' : 0, 'Sal' : 1, 'Sev' : 2, 'Maj2' : 3, 'Maj1' : 4, 'Mod' : 5, 'Min2' : 6, 'Min1' : 7, 'Typ' : 8 }, inplace = True )\n",
    "full_X[ 'GarageCond'   ].replace( { 'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "full_X[ 'GarageFinish' ].replace( { 'None' : 0, 'Unf' : 1, 'RFn' : 2, 'Fin' : 3 }, inplace = True )\n",
    "full_X[ 'GarageQual'   ].replace( { 'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "full_X[ 'HeatingQC'    ].replace( { 'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "full_X[ 'KitchenQual'  ].replace( { 'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "full_X[ 'LandSlope'    ].replace( { 'None' : 0, 'Sev' : 1, 'Mod' : 2, 'Gtl' : 3 }, inplace = True )\n",
    "full_X[ 'LandContour'  ].replace( { 'None' : 0, 'Low' : 1, 'HLS' : 2, 'Bnk' : 3, 'Lvl' : 4 }, inplace = True )\n",
    "full_X[ 'LotShape'     ].replace( { 'None' : 0, 'Reg' : 1, 'IR1' : 2, 'IR2' : 3, 'IR3' : 4 }, inplace = True )\n",
    "full_X[ 'PoolQC'       ].replace( { 'None' : 0, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "full_X[ 'PavedDrive'   ].replace( { 'None' : 0, 'N' : 1, 'P' : 2, 'Y' : 3 }, inplace = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Add Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X[ 'TotalLivAreaSF' ] =  full_X[ '1stFlrSF' ] + full_X[ '2ndFlrSF' ] + full_X[ 'TotalBsmtSF' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### BoxCox Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = list( get_categorical_features( full_X ) )\n",
    "numerical_features   = list( get_numerical_features( full_X ) )\n",
    "skew_features        = {}\n",
    "\n",
    "for feature in numerical_features:\n",
    "    skew_features[ feature ] = full_X[ feature ].skew()\n",
    "    \n",
    "skew_features = pd.DataFrame( { 'Features' : list( skew_features.keys() ), \n",
    "                                'Skew'     : list( skew_features.values() ) } )\n",
    "\n",
    "features_to_box = list( skew_features[ abs( skew_features[ 'Skew' ] ) > 0.75 ][ 'Features' ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features_to_box:\n",
    "    full_X[ [feature] ] = boxcox1p( full_X[ [feature] ], 0.15 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create One-Hot-Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X = pd.get_dummies( full_X, \n",
    "                         drop_first = True, \n",
    "                         prefix     = categorical_features, \n",
    "                         columns    = categorical_features )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Split Back to Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1458, 232) \n",
      "Test: (1459, 232)\n"
     ]
    }
   ],
   "source": [
    "train_X = pd.DataFrame( full_X[ 0:train_end ] )\n",
    "test_X  = pd.DataFrame( full_X[ train_end:test_end ] )\n",
    "\n",
    "print( \"Train: {} \\nTest: {}\".format( train_X.shape, test_X.shape ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Optimal Hyperparamters / Score Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train                       = pd.concat( [ train_X, train_y ], axis = 1 )\n",
    "X_train, X_test, y_train, y_test = train_test_split( full_train.drop( [ 'SalePrice' ], axis = 1 ), \n",
    "                                                     full_train[ 'SalePrice' ], \n",
    "                                                     test_size = 0.30, \n",
    "                                                     random_state = 42 )\n",
    "scaler         = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform( X_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_score = {\n",
    "    'XGBRegressor'              : 0,\n",
    "    'GradientBoostingRegressor' : 0,\n",
    "    'Lasso'                     : 0,\n",
    "    'KernelRidge'               : 0,\n",
    "    'ElasticNet'                : 0,\n",
    "    'LightGBM'                  : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   16.4s remaining:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   16.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'colsample_bytree': [0.45], 'gamma': [0.05], 'min_child_weight': [1.75], 'n_estimators': [2000], 'reg_alpha': [0.45], 'reg_lambda': [0.9], 'subsample': [0.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Hyperparameters after initial gridsearch\n",
    "xgbm_grid = { \n",
    "    'colsample_bytree' : [ 0.45 ], \n",
    "    'gamma'            : [ 0.05 ], \n",
    "    'min_child_weight' : [ 1.75 ], \n",
    "    'n_estimators'     : [ 2000 ],\n",
    "    'reg_alpha'        : [ 0.45 ], \n",
    "    'reg_lambda'       : [ 0.9 ],\n",
    "    'subsample'        : [ 0.5 ]\n",
    "}\n",
    "\n",
    "xgbm = GridSearchCV( XGBRegressor(), cv = 5, param_grid = xgbm_grid, n_jobs = -1, scoring = 'neg_mean_squared_error', verbose = 1 )\n",
    "xgbm.fit( X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_score[ 'XGBRegressor' ] = round( math.sqrt( -xgbm.best_score_ ), 4 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    8.5s remaining:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_sampl...=None, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [3000], 'learning_rate': [0.05], 'max_depth': [4], 'max_features': ['sqrt'], 'min_samples_leaf': [15], 'min_samples_split': [10], 'loss': ['huber']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Hyperparameters after initial gridsearch\n",
    "gbr_grid = {\n",
    "    'n_estimators'      : [ 3000 ],\n",
    "    'learning_rate'     : [ 0.05 ],\n",
    "    'max_depth'         : [ 4 ],\n",
    "    'max_features'      : [ 'sqrt' ],\n",
    "    'min_samples_leaf'  : [ 15 ], \n",
    "    'min_samples_split' : [ 10 ], \n",
    "    'loss'              : [ 'huber' ]\n",
    "}\n",
    "\n",
    "gbr = GridSearchCV( GradientBoostingRegressor(), cv = 5, param_grid = gbr_grid, n_jobs = -1, scoring = 'neg_mean_squared_error', verbose = 1 )\n",
    "gbr.fit( X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_score[ 'GradientBoostingRegressor' ] = round( math.sqrt( -gbr.best_score_ ), 4 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'alpha': [0.0005], 'max_iter': [300]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Hyperparameters after initial gridsearch\n",
    "lasso_grid = { \n",
    "    'alpha'    : [ 0.0005 ], \n",
    "    'max_iter' : [ 300 ]\n",
    "}\n",
    "\n",
    "lasso = GridSearchCV( Lasso(), cv = 5, param_grid = lasso_grid, n_jobs = -1, scoring = 'neg_mean_squared_error', verbose = 1 )\n",
    "lasso.fit( X_train_scaled, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_score[ 'Lasso' ] = round( math.sqrt( -lasso.best_score_ ), 4 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Kernel Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=KernelRidge(alpha=1, coef0=1, degree=3, gamma=None, kernel='linear',\n",
       "      kernel_params=None),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'alpha': [0.6], 'kernel': ['polynomial'], 'degree': [2], 'coef0': [2.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Hyperparameters after initial gridsearch\n",
    "kernel_grid = {\n",
    "    'alpha'  : [ 0.6 ], \n",
    "    'kernel' : [ 'polynomial' ], \n",
    "    'degree' : [ 2 ], \n",
    "    'coef0'  : [ 2.5 ]\n",
    "}\n",
    "\n",
    "kridge = GridSearchCV( KernelRidge(), cv = 5, param_grid = kernel_grid, n_jobs = -1, scoring = 'neg_mean_squared_error', verbose = 1 )\n",
    "kridge.fit( X_train_scaled, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_score[ 'KernelRidge' ] = round( math.sqrt( -kridge.best_score_ ), 4 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Hyperparameters after initial gridsearch\n",
    "elastic_grid = {\n",
    "    'alpha'        : [ 0.0005 ],\n",
    "    'l1_ratio'     : [ .9 ]\n",
    "}\n",
    "\n",
    "elastic = GridSearchCV( ElasticNet(), cv = 5, param_grid = elastic_grid, n_jobs = -1, scoring = 'neg_mean_squared_error', verbose = 1 )\n",
    "elastic.fit( X_train_scaled, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_score[ 'ElasticNet' ] = round( math.sqrt( -elastic.best_score_ ), 4 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_grid = {\n",
    "    'objective'               : [ 'regression' ],\n",
    "    'num_leaves'              : [ 5 ],\n",
    "    'learning_rate'           : [ 0.05 ], \n",
    "    'n_estimators'            : [ 750 ],\n",
    "    'max_bin'                 : [ 50 ],\n",
    "    'bagging_fraction'        : [ 0.75 ],\n",
    "    'bagging_freq'            : [ 5 ], \n",
    "    'feature_fraction'        : [ 0.25 ]\n",
    "    'min_data_in_leaf'        : [ 5 ], \n",
    "    'min_sum_hessian_in_leaf' : [ 10 ]\n",
    "}\n",
    "\n",
    "lgbm = GridSearchCV( lgb.LGBMRegressor(), cv = 5, param_grid = lgbm_grid, n_jobs = -1, scoring = 'neg_mean_squared_error', verbose = 1 )\n",
    "lgbm.fit( X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_score[ 'LightGBM' ] = round( math.sqrt( -lgbm.best_score_ ), 4 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Review RMSE Scores of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame( { 'RMSE' : rmse_score }, index = rmse_score.keys() ).sort_values( by = [ 'RMSE' ], ascending = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Selected Model on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBRegressor\n",
    "# ==========\n",
    "xgbm_model = XGBRegressor(\n",
    "    colsample_bytree = xgbm.best_estimator_.colsample_bytree,\n",
    "    gamma            = xgbm.best_estimator_.gamma,\n",
    "    min_child_weight = xgbm.best_estimator_.min_child_weight,\n",
    "    n_estimators     = xgbm.best_estimator_.n_estimators,\n",
    "    reg_alpha        = xgbm.best_estimator_.reg_alpha,\n",
    "    reg_lambda       = xgbm.best_estimator_.reg_lambda,\n",
    "    subsample        = xgbm.best_estimator_.subsample\n",
    ")\n",
    "\n",
    "# GradientBoostingRegressor\n",
    "# ==================================================\n",
    "gbr_model = GradientBoostingRegressor( \n",
    "    n_estimators      = gbr.best_estimator_.n_estimators,\n",
    "    learning_rate     = gbr.best_estimator_.learning_rate,\n",
    "    max_depth         = gbr.best_estimator_.max_depth,\n",
    "    max_features      = gbr.best_estimator_.max_features,\n",
    "    min_samples_leaf  = gbr.best_estimator_.min_samples_leaf,\n",
    "    min_samples_split = gbr.best_estimator_.min_samples_split,\n",
    "    loss              = gbr.best_estimator_.loss\n",
    ")\n",
    "\n",
    "# Lasso\n",
    "# ==================================================\n",
    "lasso_model = make_pipeline( RobustScaler(), Lasso(\n",
    "    alpha    = lasso.best_estimator_.alpha,\n",
    "    max_iter = lasso.best_estimator_.max_iter\n",
    ") )\n",
    "\n",
    "# KernelRidge\n",
    "# ==================================================\n",
    "kridge_model = make_pipeline( RobustScaler(), KernelRidge(\n",
    "    alpha  = kridge.best_estimator_.alpha,\n",
    "    kernel = kridge.best_estimator_.kernel,\n",
    "    degree = kridge.best_estimator_.degree,\n",
    "    coef0  = kridge.best_estimator_.coef0\n",
    ") )\n",
    "\n",
    "# ElasticNet\n",
    "# ==================================================\n",
    "elastic_model = make_pipeline( RobustScaler(), ElasticNet(\n",
    "    alpha    = elastic.best_estimator_.alpha,\n",
    "    l1_ratio = elastic.best_estimator_.l1_ratio\n",
    ") )\n",
    "\n",
    "# LightGBM\n",
    "# ==================================================\n",
    "lgbm_model = lgb.LGBMRegressor(\n",
    "    objective               = lgbm.best_estimator_.objective,\n",
    "    num_leaves              = lgbm.best_estimator_.num_leaves,\n",
    "    learning_rate           = lgbm.best_estimator_.learning_rate,\n",
    "    n_estimators            = lgbm.best_estimator_.n_estimators,\n",
    "    max_bin                 = lgbm.best_estimator_.max_bin,\n",
    "    bagging_fraction        = lgbm.best_estimator_.bagging_fraction,\n",
    "    bagging_freq            = lgbm.best_estimator_.bagging_freq,\n",
    "    feature_fraction        = lgbm.best_estimator_.feature_fraction,\n",
    "    min_data_in_leaf        = lgbm.best_estimator_.min_data_in_leaf,\n",
    "    min_sum_hessian_in_leaf = lgbm.best_estimator_.min_sum_hessian_in_leaf,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_model = StackingCVRegressor( regressors     = ( lasso_model, gbr_model, kridge_model, lgbm_model, xgbm_model ),\n",
    "                                     meta_regressor = elastic_model,\n",
    "                                     cv = 5 )\n",
    "\n",
    "stacked_model.fit( train_X.values, train_y.values )\n",
    "stacked_predict = np.expm1( stacked_model.predict( test_X.values ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(\n",
    "    { 'Id'        : test_raw[ 'Id' ],\n",
    "      'SalePrice' : stacked_predict } \n",
    ")\n",
    "\n",
    "submission.to_csv( '.\\\\ames_housing_submission.csv', index = False )\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
