{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ames Housing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing       import RobustScaler\n",
    "from sklearn.model_selection     import train_test_split\n",
    "from sklearn.model_selection     import GridSearchCV\n",
    "from sklearn.metrics             import mean_squared_error\n",
    "from xgboost                     import XGBRegressor\n",
    "from xgboost                     import plot_importance\n",
    "from sklearn.ensemble            import RandomForestRegressor\n",
    "from sklearn.linear_model        import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option( 'display.max_columns', None )\n",
    "sns.set( rc = { 'figure.figsize' : ( 24, 5 ) } )\n",
    "warnings.filterwarnings( 'ignore' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical_features( df ):\n",
    "    return df.select_dtypes( include = [ 'int64', 'float64' ] ).columns\n",
    "\n",
    "def get_categorical_features( df ):\n",
    "    return df.select_dtypes( include = [ 'object' ] ).columns\n",
    "\n",
    "def return_features_with_null( df ):\n",
    "    still_missing = pd.DataFrame( len( df[ get_categorical_features ] ) - df[ get_categorical_features ].count() )\n",
    "    return pd.DataFrame( still_missing[ still_missing[ 0 ] > 0 ] )\n",
    "\n",
    "def return_rows_with_null( df ):\n",
    "    null_columns = df.columns[ df.isnull().any() ]\n",
    "    print( pd.DataFrame( df[ df.isnull().any( axis = 1 ) ][ null_columns ].head( 10 ) ) )\n",
    "\n",
    "def na_heatmap( df ):\n",
    "    df      = df[ sorted( df.columns ) ]\n",
    "    fig, ax = plt.subplots( figsize = ( 25, 5 ) )\n",
    "    sns.heatmap( df.isnull(), yticklabels = False, cbar = False )\n",
    "    \n",
    "def get_facet_grid( df, feature_type ):\n",
    "    if feature_type == 'numerical':\n",
    "        facet_grid = pd.melt( df, value_vars = sorted( get_numerical_features( df ) ) )\n",
    "        grid_plot  = sns.FacetGrid( facet_grid, col = 'variable', col_wrap = 10, sharex = False, sharey = False)\n",
    "        grid_plot  = grid_plot.map( sns.distplot, 'value' )\n",
    "        \n",
    "        return grid_plot\n",
    "    \n",
    "    elif feature_type == 'categorical':\n",
    "        facet_grid = pd.melt( df, value_vars = sorted( get_categorical_features( df ) ) )\n",
    "        grid_plot  = sns.FacetGrid( facet_grid, col = 'variable', col_wrap = 10, sharex = False, sharey = False )\n",
    "        grid_plot  = grid_plot.map( sns.countplot, 'value' )\n",
    "\n",
    "        plt.xticks( rotation = 'vertical' )\n",
    "        [ plt.setp( ax.get_xticklabels(), rotation = 60 ) for ax in grid_plot.axes.flat ]\n",
    "        grid_plot.fig.tight_layout()\n",
    "        \n",
    "        return grid_plot\n",
    "    \n",
    "    else:\n",
    "        print( 'Please specify \"numerical\" of \"categorical\"' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.getcwd() + '\\\\..\\\\..\\\\..\\\\data\\\\ames_housing\\\\'\n",
    "train_raw = pd.read_csv( data_path + 'train.csv' )\n",
    "test_raw  = pd.read_csv( data_path + 'test.csv' )\n",
    "\n",
    "train_X = train_raw.drop( [ 'SalePrice', 'Id' ], axis = 1 )\n",
    "train_y = train_raw[ 'SalePrice' ]\n",
    "test_X  = test_raw.drop( [ 'Id' ], axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print( \"Train: {} \\nTest: {}\".format( train_X.shape, test_X.shape ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X    = pd.concat( [train_X, test_X] )\n",
    "train_end = len( train_X )\n",
    "test_end  = len( full_X )\n",
    "\n",
    "# print( full_X.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_facet_grid( full_X, 'numerical' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_facet_grid( full_X, 'categorical' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# na_heatmap( train_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.log1p( train_y )\n",
    "# sns.distplot( train_y, bins = 75 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Make Ranked Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking from Kaggle data info\n",
    "def convert_to_ranked( df ):\n",
    "    df[ 'Alley'        ].replace( { 'Grvl' : 1, 'Pave' : 2 }, inplace = True )\n",
    "    df[ 'BsmtCond'     ].replace( { 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4 }, inplace = True )\n",
    "    df[ 'BsmtExposure' ].replace( { 'No' : 1, 'Mn' : 2, 'Av' : 3, 'Gd' : 4 }, inplace = True )\n",
    "    df[ 'BsmtFinType1' ].replace( { 'Unf' : 1, 'LwQ' : 2, 'Rec' : 3, 'BLQ' : 4, 'ALQ' : 5, 'GLQ' : 6 }, inplace = True )\n",
    "    df[ 'BsmtFinType2' ].replace( { 'Unf' : 1, 'LwQ' : 2, 'Rec' : 3, 'BLQ' : 4, 'ALQ' : 5, 'GLQ' : 6 }, inplace = True )\n",
    "    df[ 'BsmtQual'     ].replace( { 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "    df[ 'ExterCond'    ].replace( { 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "    df[ 'ExterQual'    ].replace( { 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "    df[ 'Fence'        ].replace( { 'MnWw' : 1, 'GdWo' : 2, 'MnPrv' : 3, 'GdPrv' : 4 }, inplace = True )\n",
    "    df[ 'FireplaceQu'  ].replace( { 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "    df[ 'Functional'   ].replace( { 'Sal' : 1, 'Sev' : 2, 'Maj2' : 3, 'Maj1' : 4, 'Mod' : 5, 'Min2' : 6, 'Min1' : 7, 'Typ' : 8 }, inplace = True )\n",
    "    df[ 'GarageCond'   ].replace( { 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "    df[ 'GarageFinish' ].replace( { 'Unf' : 1, 'RFn' : 2, 'Fin' : 3 }, inplace = True )\n",
    "    df[ 'GarageQual'   ].replace( { 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "    df[ 'HeatingQC'    ].replace( { 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "    df[ 'KitchenQual'  ].replace( { 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "    df[ 'LandSlope'    ].replace( { 'Sev' : 1, 'Mod' : 2, 'Gtl' : 3 }, inplace = True )\n",
    "    df[ 'LandContour'  ].replace( { 'Low' : 1, 'HLS' : 2, 'Bnk' : 3, 'Lvl' : 4 }, inplace = True )\n",
    "    df[ 'LotShape'     ].replace( { 'Reg' : 1, 'IR1' : 2, 'IR2' : 3, 'IR3' : 4 }, inplace = True )\n",
    "    df[ 'PoolQC'       ].replace( { 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "    df[ 'PavedDrive'   ].replace( { 'N' : 1, 'P' : 2, 'Y' : 3 }, inplace = True )\n",
    "    df[ 'Utilities'    ].replace( { 'ELO' : 1, 'NoSeWa' : 2, 'NoSewr' : 3, 'AllPub' : 4 }, inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_ranked( full_X )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X[ 'TotalLivAreaSF' ] = full_X[ '1stFlrSF'     ] + full_X[ '2ndFlrSF' ]\n",
    "full_X[ 'TotalOtherSF' ]   = full_X[ 'TotalBsmtSF'  ] + full_X[ 'GrLivArea' ] \n",
    "full_X[ 'TotalBath'   ]    = full_X[ 'BsmtFullBath' ] + ( 0.5 * full_X[ 'BsmtHalfBath' ] ) + full_X[ 'FullBath' ] + ( 0.5 * full_X[ 'HalfBath' ] )\n",
    "full_X[ 'TotalPorchSF' ]   = full_X[ 'OpenPorchSF'  ] + full_X[ 'EnclosedPorch' ] + full_X[ '3SsnPorch' ] + full_X[ 'ScreenPorch' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Make Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_category( df ):\n",
    "    df[ 'MSSubClass' ].replace( { 20 : '20', 30 : '30', 40 : '40', 45 : '45', 50 : '50', 60 : '60',\n",
    "                                  70 : '70', 75 : '75', 80 : '80', 85 : '85', 90 : '90', 120 : '120',\n",
    "                                  150 : '150', 160 : '160', 180 : '180', 190 : '190' }, inplace = True )\n",
    "    \n",
    "    df[ 'MoSold' ].replace( { 1 : 'Jan', 2 : 'Feb', 3 : 'Mar', 4 : 'Apr', 5 : 'May', 6 : 'Jun', \n",
    "                              7 : 'Jul', 8 : 'Aug', 9 : 'Sep', 10 : 'Oct', 11 : 'Nov', 12 : 'Dec' }, inplace = True )\n",
    "    \n",
    "    df[ 'YrSold' ].replace( { 2006 : '2006', 2007 : '2007', 2008 : '2008', 2009 : '2009', 2010 : '2010'  }, inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_category( full_X )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Replace Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# na_heatmap( full_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_with_none = [ 'Alley', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'BsmtQual', 'Fence', 'FireplaceQu', \n",
    "                   'Functional', 'GarageCond', 'GarageFinish', 'GarageQual', 'GarageType', 'KitchenQual', 'MasVnrType', 'MiscFeature', 'PoolQC' ]\n",
    "\n",
    "fill_with_zero = [ 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtFullBath', 'BsmtHalfBath', 'BsmtUnfSF', 'GarageArea', 'GarageCars', 'TotalBsmtSF', 'GarageYrBlt', 'MasVnrArea', 'TotalBath', 'TotalOtherSF' ]\n",
    "\n",
    "full_X[ fill_with_none ] = full_X[ fill_with_none ].fillna( 'None' )\n",
    "full_X[ fill_with_zero ] = full_X[ fill_with_zero ].fillna( 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = full_X[ 0:train_end ]\n",
    "test_X  = full_X[ train_end:test_end ]\n",
    "\n",
    "# print( \"Train: {} \\nTest: {}\".format( train_X.shape, test_X.shape ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fill Value with Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X[ 'Utilities' ].fillna( train_X[ 'Utilities' ].mode()[0], inplace = True )\n",
    "test_X[ 'Utilities' ].fillna( test_X[ 'Utilities' ].mode()[0], inplace = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fill with Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X[ 'LotFrontage' ] = train_X.groupby( 'Neighborhood' )[ 'LotFrontage' ].transform( lambda x: x.fillna( x.median() ) )\n",
    "test_X[ 'LotFrontage' ] = test_X.groupby( 'Neighborhood' )[ 'LotFrontage' ].transform( lambda x: x.fillna( x.median() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return_features_with_null( train_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return_features_with_null( test_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return_rows_with_null( full_X )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fill Remaining Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_train = [ 'Electrical' ]\n",
    "missing_test  = [ 'MSZoning', 'Exterior1st', 'Exterior2nd', 'SaleType' ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X[ missing_train ] = train_X[ missing_train ].fillna( train_X.mode().iloc[0] )\n",
    "test_X[ missing_test ]   = test_X[ missing_test ].fillna( test_X.mode().iloc[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X = pd.concat( [train_X, test_X] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fix Skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_facet_grid( full_X, 'numerical' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_pos_skew( feature ):\n",
    "    return np.log1p( full_X[ feature ] + 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_log = [ '1stFlrSF', 'BsmtUnfSF', 'GarageArea', 'GrLivArea', 'LotArea', 'LotFrontage', 'MiscVal', 'TotalBsmtSF', 'TotalOtherSF', 'TotalLivAreaSF' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features_to_log:\n",
    "    full_X[ feature ] = fix_pos_skew( feature )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_facet_grid( full_X[ features_to_log ], 'numerical' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Handle Incorrect Data Input (Test Garage Year Built)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print( max( full_X[ 'GarageYrBlt' ] ) )\n",
    "# print( sorted( full_X[ 'GarageYrBlt' ], reverse = True )[ 0:5 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_index                              = full_X.loc[ full_X[ 'GarageYrBlt' ] == 2207.0 ].index[0]\n",
    "full_X.loc[ target_index, 'GarageYrBlt' ] = round( np.mean( full_X[ 'GarageYrBlt' ] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print( max( full_X[ 'GarageYrBlt' ] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create One-Hot-Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_data                  = [ 'BedroomAbvGr', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'TotalBath', 'Fireplaces', 'GarageCars', 'KitchenAbvGr', 'TotRmsAbvGrd' ]\n",
    "numerical_features          = list( get_numerical_features( full_X ) )\n",
    "numerical_features_to_scale = [ x for x in numerical_features if x not in count_data ]\n",
    "categorical_features        = list( get_categorical_features( full_X ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X = pd.get_dummies( full_X, drop_first = True, prefix = categorical_features, columns = categorical_features )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Split Back to Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.DataFrame( full_X[ 0:train_end ] )\n",
    "test_X  = pd.DataFrame( full_X[ train_end:test_end ] )\n",
    "\n",
    "# print( \"Train: {} \\nTest: {}\".format( train_X.shape, test_X.shape ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "\n",
    "train_X[ numerical_features_to_scale ] = scaler.fit_transform( train_X[ numerical_features_to_scale ], train_y ) \n",
    "test_X[ numerical_features_to_scale ]  = scaler.transform( test_X[ numerical_features_to_scale ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build & Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( train_X, train_y, test_size = 0.33, random_state = 42 )\n",
    "# # print( \"Train: {} \\nTest: {}\".format( X_train.shape, X_test.shape ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_scores = { 'XGBoost'     : 0,\n",
    "                'XGBoostSlim' : 0,\n",
    "                'Lasso'       : 0 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    4.3s remaining:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'learning_rate': [0.1], 'max_depth': [4], 'subsample': [0.75], 'colsample_bytree': [1], 'n_estimators': [100], 'reg_alpha': [0], 'reg_lambda': [0.25]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the params that ended up being th best after an initial grid search\n",
    "param_grid = { 'learning_rate'    : [ 0.1 ],\n",
    "               'max_depth'        : [ 4 ],\n",
    "               'subsample'        : [ 0.75 ],\n",
    "               'colsample_bytree' : [ 1 ],\n",
    "               'n_estimators'     : [ 100 ],\n",
    "               'reg_alpha'        : [ 0 ],\n",
    "               'reg_lambda'       : [ 0.25 ] }\n",
    "\n",
    "xgbm = GridSearchCV( XGBRegressor(), cv = 5, param_grid = param_grid, n_jobs = -1, scoring = 'neg_mean_squared_error', verbose = 1 )\n",
    "xgbm.fit( X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgbm.predict( X_test )\n",
    "rmse_scores[ 'XGBoost' ] = math.sqrt( mean_squared_error( y_test, y_pred ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### XGBoost Slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=0.25, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.75)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the params that ended up being th best after an initial grid search\n",
    "xgb = XGBRegressor( learning_rate    =  0.1,\n",
    "                    max_depth        =  4,\n",
    "                    subsample        =  0.75,\n",
    "                    colsample_bytree =  1,\n",
    "                    n_estimators     =  100,\n",
    "                    reg_alpha        =  0,\n",
    "                    reg_lambda       =  0.25 )\n",
    "\n",
    "xgb.fit( train_X, train_y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "result             = pd.DataFrame( { 'Feature' : X_train.columns, 'Importance' : xgb.feature_importances_ } )\n",
    "result             = result.sort_values( by = [ 'Importance' ], ascending = False ).reset_index( drop = True )\n",
    "important_features = list( result[ result[ 'Importance' ] > 0.004 ][ 'Feature' ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( X_train.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy = X_train[ important_features ].copy()\n",
    "X_test_copy  = X_test[ important_features ].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( X_train_copy.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.5, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=1, missing=None, n_estimators=200,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=0.25, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.5)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor( learning_rate    =  0.1,\n",
    "                    max_depth        =  4,\n",
    "                    subsample        =  0.5,\n",
    "                    colsample_bytree =  0.5,\n",
    "                    n_estimators     =  200,\n",
    "                    reg_alpha        =  0,\n",
    "                    reg_lambda       =  0.25 )\n",
    "\n",
    "xgb.fit( X_train_copy, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb.predict( X_test_copy )\n",
    "rmse_scores[ 'XGBoostSlim' ] = math.sqrt( mean_squared_error( y_test, y_pred ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of   5 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=6,\n",
       "       param_grid={'alpha': [0.001], 'max_iter': [750]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the params that ended up being th best after an initial grid search\n",
    "param_grid = { 'alpha'    : [ 0.001 ], \n",
    "               'max_iter' : [ 750 ] }\n",
    "\n",
    "lasso = GridSearchCV( Lasso(), cv = 5, param_grid = param_grid, n_jobs = 6, scoring = 'neg_mean_squared_error', verbose = 1 )\n",
    "lasso.fit( X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lasso.predict( X_test )\n",
    "rmse_scores[ 'Lasso' ] = math.sqrt( mean_squared_error( y_test, y_pred ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review RMSE Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>XGBoostSlim</th>\n",
       "      <th>Lasso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.139345</td>\n",
       "      <td>0.130509</td>\n",
       "      <td>0.129009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    XGBoost  XGBoostSlim     Lasso\n",
       "1  0.139345     0.130509  0.129009"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame( rmse_scores, columns = list( rmse_scores.keys() ), index = [ 1 ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Selected Model on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001, 'max_iter': 750}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=6,\n",
       "       param_grid={'alpha': [0.001], 'max_iter': [5000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the params that ended up being th best after an initial grid search\n",
    "param_grid = { 'alpha'    : [ 0.001 ], \n",
    "               'max_iter' : [ 5000 ] }\n",
    "\n",
    "lasso = GridSearchCV( Lasso(), cv = 10, param_grid = param_grid, n_jobs = 6, scoring = 'neg_mean_squared_error', verbose = 1 )\n",
    "lasso.fit( train_X, train_y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.exp( lasso.predict( test_X ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>110839.353775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>154453.949230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>183257.659738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>204060.062722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>195683.528401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  110839.353775\n",
       "1  1462  154453.949230\n",
       "2  1463  183257.659738\n",
       "3  1464  204060.062722\n",
       "4  1465  195683.528401"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(\n",
    "    { 'Id'        : test_raw[ 'Id' ],\n",
    "      'SalePrice' : predictions } \n",
    ")\n",
    "\n",
    "submission.to_csv( '.\\\\ames_housing_submit.csv', index = False )\n",
    "submission.head( 5 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
