{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ames Housing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default Libraries\n",
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sns\n",
    "\n",
    "# Model Selection\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "from sklearn.preprocessing   import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics         import mean_squared_error\n",
    "from scipy.special           import boxcox1p\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from xgboost                 import XGBRegressor, plot_importance\n",
    "from sklearn.ensemble        import GradientBoostingRegressor\n",
    "from sklearn.base            import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.linear_model    import Lasso, Ridge, ElasticNet\n",
    "from sklearn.pipeline        import make_pipeline\n",
    "from sklearn.kernel_ridge    import KernelRidge\n",
    "from mlxtend.regressor       import StackingCVRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option( 'display.max_columns', None )\n",
    "sns.set( rc = { 'figure.figsize' : ( 10, 5 ) } )\n",
    "warnings.filterwarnings( 'ignore' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical_features( df ):\n",
    "    return df.select_dtypes( include = [ 'int64', 'float64' ] ).columns\n",
    "\n",
    "def get_categorical_features( df ):\n",
    "    return df.select_dtypes( include = [ 'object' ] ).columns\n",
    "\n",
    "def return_features_with_null( df ):\n",
    "    still_missing = pd.DataFrame( len( df[ get_categorical_features ] ) - df[ get_categorical_features ].count() )\n",
    "    return pd.DataFrame( still_missing[ still_missing[ 0 ] > 0 ] )\n",
    "\n",
    "def return_rows_with_null( df ):\n",
    "    null_columns = df.columns[ df.isnull().any() ]\n",
    "    print( pd.DataFrame( df[ df.isnull().any( axis = 1 ) ][ null_columns ].head( 10 ) ) )\n",
    "\n",
    "def na_heatmap( df ):\n",
    "    df      = df[ sorted( df.columns ) ]\n",
    "    fig, ax = plt.subplots( figsize = ( 25, 5 ) )\n",
    "    sns.heatmap( df.isnull(), yticklabels = False, cbar = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.getcwd() + '\\\\..\\\\..\\\\..\\\\data\\\\ames_housing\\\\'\n",
    "train_raw = pd.read_csv( data_path + 'train.csv' )\n",
    "test_raw  = pd.read_csv( data_path + 'test.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1460, 81) \n",
      "Test: (1459, 80)\n"
     ]
    }
   ],
   "source": [
    "print( \"Train: {} \\nTest: {}\".format( train_raw.shape, test_raw.shape ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X.head( 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facet_grid = pd.melt( df, value_vars = sorted( get_numerical_features( df ) ) )\n",
    "# grid_plot  = sns.FacetGrid( facet_grid, col = 'variable', col_wrap = 10, sharex = False, sharey = False)\n",
    "# grid_plot.map( sns.distplot, 'value' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facet_grid = pd.melt( df, value_vars = sorted( get_categorical_features( df ) ) )\n",
    "# grid_plot  = sns.FacetGrid( facet_grid, col = 'variable', col_wrap = 10, sharex = False, sharey = False )\n",
    "# grid_plot  = grid_plot.map( sns.countplot, 'value' )\n",
    "\n",
    "# plt.xticks( rotation = 'vertical' )\n",
    "# [ plt.setp( ax.get_xticklabels(), rotation = 60 ) for ax in grid_plot.axes.flat ]\n",
    "# grid_plot.fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplots( figsize = ( 15, 15 ) )\n",
    "# sns.heatmap( train_X.corr(), vmax = 1, square = True, cmap = 'magma', linecolor = 'white', linewidth = 0.1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Correct Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.scatterplot( x = 'GrLivArea', y = 'SalePrice', data = train_raw )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = train_raw.drop( train_raw[ ( train_raw[ 'GrLivArea' ] > 4000 ) & ( train_raw[ 'SalePrice' ] < 250000 ) ].index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_raw.drop( [ 'SalePrice', 'Id' ], axis = 1 )\n",
    "train_y = train_raw[ 'SalePrice' ]\n",
    "test_X  = test_raw.drop( [ 'Id' ], axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Transform Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot( train_y, bins = 75 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skew: 1.8813 \n",
      "Kurtosis: 6.5231\n"
     ]
    }
   ],
   "source": [
    "print( 'Skew: {} \\nKurtosis: {}'.format( round( train_y.skew(), 4 ), \n",
    "                                         round( train_y.kurtosis(), 4 ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.log1p( train_y )\n",
    "# sns.distplot( train_y, bins = 75 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skew: 0.1216 \n",
      "Kurtosis: 0.8048\n"
     ]
    }
   ],
   "source": [
    "print( 'Skew: {} \\nKurtosis: {}'.format( round( train_y.skew(), 4 ), \n",
    "                                         round( train_y.kurtosis(), 4 ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2917, 79)\n"
     ]
    }
   ],
   "source": [
    "full_X    = pd.concat( [train_X, test_X] )\n",
    "train_end = len( train_X )\n",
    "test_end  = len( full_X )\n",
    "\n",
    "print( full_X.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# na_heatmap( full_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = list( get_categorical_features( full_X ) )\n",
    "numerical_features   = list( get_numerical_features( full_X ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Replace Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# na_heatmap( full_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_with_none = [ 'Alley', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'BsmtQual', 'Fence', 'FireplaceQu', \n",
    "                   'GarageCond', 'GarageFinish', 'GarageQual', 'GarageType', 'MasVnrType', 'MiscFeature', 'MSSubClass', 'PoolQC' ]\n",
    "\n",
    "fill_with_zero = [ 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtFullBath', 'BsmtHalfBath', 'BsmtUnfSF', 'GarageArea', 'GarageCars', 'TotalBsmtSF', 'GarageYrBlt', 'MasVnrArea' ]\n",
    "\n",
    "full_X[ fill_with_none ] = full_X[ fill_with_none ].fillna( 'None' )\n",
    "full_X[ fill_with_zero ] = full_X[ fill_with_zero ].fillna( 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Drop Useless Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9989715461090161"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( full_X[ full_X[ 'Utilities' ] == 'AllPub' ] ) / len( full_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X = full_X.drop( [ 'Utilities' ], axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Impute Remaining NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle says NA is Typ, which after ranking is value 8\n",
    "full_X[ 'Functional' ] = full_X[\"Functional\"].fillna( 'Typ' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_with_mode           = [ 'Electrical', 'KitchenQual', 'Exterior1st', 'Exterior2nd', 'SaleType', 'MSZoning' ]\n",
    "full_X[ missing_with_mode ] = full_X[ missing_with_mode ].fillna( full_X.mode().iloc[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X[ 'LotFrontage' ] = full_X.groupby( 'Neighborhood' )[ 'LotFrontage' ].transform( lambda x: x.fillna( x.median() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return_features_with_null( full_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return_rows_with_null( full_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X[ 'MSSubClass' ]  = full_X['MSSubClass'].apply(str)\n",
    "full_X[ 'OverallCond' ] = full_X['OverallCond'].astype(str)\n",
    "full_X[ 'YrSold' ]      = full_X['YrSold'].astype(str)\n",
    "full_X[ 'MoSold' ]      = full_X['MoSold'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create Ranked Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X[ 'Alley'        ].replace( { 'None' : 0, 'Grvl' : 1, 'Pave' : 2 }, inplace = True )\n",
    "full_X[ 'BsmtCond'     ].replace( { 'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4 }, inplace = True )\n",
    "full_X[ 'BsmtExposure' ].replace( { 'None' : 0, 'No' : 1, 'Mn' : 2, 'Av' : 3, 'Gd' : 4 }, inplace = True )\n",
    "full_X[ 'BsmtFinType1' ].replace( { 'None' : 0, 'Unf' : 1, 'LwQ' : 2, 'Rec' : 3, 'BLQ' : 4, 'ALQ' : 5, 'GLQ' : 6 }, inplace = True )\n",
    "full_X[ 'BsmtFinType2' ].replace( { 'None' : 0, 'Unf' : 1, 'LwQ' : 2, 'Rec' : 3, 'BLQ' : 4, 'ALQ' : 5, 'GLQ' : 6 }, inplace = True )\n",
    "full_X[ 'BsmtQual'     ].replace( { 'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "full_X[ 'ExterCond'    ].replace( { 'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "full_X[ 'ExterQual'    ].replace( { 'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "full_X[ 'Fence'        ].replace( { 'None' : 0, 'MnWw' : 1, 'GdWo' : 2, 'MnPrv' : 3, 'GdPrv' : 4 }, inplace = True )\n",
    "full_X[ 'FireplaceQu'  ].replace( { 'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "full_X[ 'Functional'   ].replace( { 'None' : 0, 'Sal' : 1, 'Sev' : 2, 'Maj2' : 3, 'Maj1' : 4, 'Mod' : 5, 'Min2' : 6, 'Min1' : 7, 'Typ' : 8 }, inplace = True )\n",
    "full_X[ 'GarageCond'   ].replace( { 'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "full_X[ 'GarageFinish' ].replace( { 'None' : 0, 'Unf' : 1, 'RFn' : 2, 'Fin' : 3 }, inplace = True )\n",
    "full_X[ 'GarageQual'   ].replace( { 'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "full_X[ 'HeatingQC'    ].replace( { 'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "full_X[ 'KitchenQual'  ].replace( { 'None' : 0, 'Po' : 1, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "full_X[ 'LandSlope'    ].replace( { 'None' : 0, 'Sev' : 1, 'Mod' : 2, 'Gtl' : 3 }, inplace = True )\n",
    "full_X[ 'LandContour'  ].replace( { 'None' : 0, 'Low' : 1, 'HLS' : 2, 'Bnk' : 3, 'Lvl' : 4 }, inplace = True )\n",
    "full_X[ 'LotShape'     ].replace( { 'None' : 0, 'Reg' : 1, 'IR1' : 2, 'IR2' : 3, 'IR3' : 4 }, inplace = True )\n",
    "full_X[ 'PoolQC'       ].replace( { 'None' : 0, 'Fa' : 2, 'TA' : 3, 'Gd' : 4, 'Ex' : 5 }, inplace = True )\n",
    "full_X[ 'PavedDrive'   ].replace( { 'None' : 0, 'N' : 1, 'P' : 2, 'Y' : 3 }, inplace = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Add Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X[ 'TotalLivAreaSF' ] = full_X[ '1stFlrSF'     ] + full_X[ '2ndFlrSF' ]\n",
    "full_X[ 'TotalOtherSF' ]   = full_X[ 'TotalBsmtSF'  ] + full_X[ 'GrLivArea' ] \n",
    "full_X[ 'TotalBath'   ]    = full_X[ 'BsmtFullBath' ] + ( 0.5 * full_X[ 'BsmtHalfBath' ] ) + full_X[ 'FullBath' ] + ( 0.5 * full_X[ 'HalfBath' ] )\n",
    "full_X[ 'TotalPorchSF' ]   = full_X[ 'OpenPorchSF'  ] + full_X[ 'EnclosedPorch' ] + full_X[ '3SsnPorch' ] + full_X[ 'ScreenPorch' ]\n",
    "\n",
    "full_X['HasBasement']  =  full_X[ 'TotalBsmtSF' ].apply(lambda x: 1 if x > 0 else 0)\n",
    "full_X['HasGarage']    =  full_X[ 'GarageArea' ].apply(lambda x: 1 if x > 0 else 0)\n",
    "full_X['HasPorch']     =  full_X[ 'TotalPorchSF' ].apply(lambda x: 1 if x > 0 else 0)\n",
    "full_X['HasPool']      =  full_X[ 'PoolArea' ].apply(lambda x: 1 if x > 0 else 0)\n",
    "full_X['WasRemodeled'] = (full_X[ 'YearRemodAdd' ] != full_X[ 'YearBuilt' ] ).astype(np.int64)\n",
    "full_X['IsNew']        = (full_X[ 'YearBuilt' ] > 2000).astype(np.int64)\n",
    "full_X['WasCompleted'] = (full_X[ 'SaleCondition' ] != 'Partial').astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### BoxCox Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feats = get_numerical_features( full_X )\n",
    "skew_features = {}\n",
    "\n",
    "for feature in numeric_feats:\n",
    "    skew_features[ feature ] = full_X[ feature ].skew()\n",
    "    \n",
    "skew_features = pd.DataFrame( { 'Features' : list( skew_features.keys() ), \n",
    "                                'Skew'     : list( skew_features.values() ) } )\n",
    "\n",
    "features_to_box = list( skew_features[ abs( skew_features[ 'Skew' ] ) > 0.75 ][ 'Features' ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features_to_box:\n",
    "    full_X[ [feature] ] = boxcox1p( full_X[ [feature] ], 0.15 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_log = pd.DataFrame( { 'Kurtosis' : round( full_X.kurtosis(), 4 ), 'Skew' : full_X.skew() } )\n",
    "features_to_log = list( np.setdiff1d( list( features_to_log[ features_to_log[ 'Kurtosis' ] > 1.15 ].index ), categorical_features ) )\n",
    "features_to_log.remove( 'MSSubClass' )\n",
    "features_to_log.remove( 'OverallCond' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features_to_log:\n",
    "    full_X[ [feature] ] = np.log1p( full_X[ [feature] ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create One-Hot-Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = list( get_categorical_features( full_X ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X = pd.get_dummies( full_X, \n",
    "                         drop_first = True, \n",
    "                         prefix     = categorical_features, \n",
    "                         columns    = categorical_features )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Split Back to Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1458, 242) \n",
      "Test: (1459, 242)\n"
     ]
    }
   ],
   "source": [
    "train_X = pd.DataFrame( full_X[ 0:train_end ] )\n",
    "test_X  = pd.DataFrame( full_X[ train_end:test_end ] )\n",
    "\n",
    "print( \"Train: {} \\nTest: {}\".format( train_X.shape, test_X.shape ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "\n",
    "train_X = scaler.fit_transform( train_X )\n",
    "test_X  = scaler.fit( test_X )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build & Compare Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgbm_grid = { \n",
    "#     'learning_rate'    : [ 0.1 ],\n",
    "#     'max_depth'        : [ 4 ],\n",
    "#     'subsample'        : [ 0.75 ],\n",
    "#     'colsample_bytree' : [ 1 ],\n",
    "#     'n_estimators'     : [ 100 ],\n",
    "#     'reg_alpha'        : [ 0 ],\n",
    "#     'reg_lambda'       : [ 0.25 ] \n",
    "# }\n",
    "\n",
    "# xgbm = GridSearchCV( XGBRegressor(), cv = 5, param_grid = xgbm_grid, n_jobs = -1, scoring = 'neg_mean_squared_error', verbose = 1 )\n",
    "# xgbm.fit( train_X, train_y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbr_grid = {\n",
    "#     'n_estimators'      : [ 3500 ],\n",
    "#     'learning_rate'     : [ 0.025 ],\n",
    "#     'max_depth'         : [ 3 ],\n",
    "#     'max_features'      : [ 'log2' ],\n",
    "#     'min_samples_leaf'  : [ 10 ],\n",
    "#     'min_samples_split' : [ 2 ],\n",
    "#     'loss'              : [ 'huber' ]\n",
    "# }\n",
    "\n",
    "# gbr = GridSearchCV( GradientBoostingRegressor(), cv = 5, param_grid = gbr_grid, n_jobs = -1, scoring = 'neg_mean_squared_error', verbose = 1 )\n",
    "# gbr.fit( train_X, train_y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso_grid = { \n",
    "#     'alpha'    : [ 0.00058 ], \n",
    "#     'max_iter' : [ 300 ] \n",
    "# }\n",
    "\n",
    "# lasso = GridSearchCV( Lasso(), cv = 5, param_grid = lasso_grid, n_jobs = -1, scoring = 'neg_mean_squared_error', verbose = 1 )\n",
    "# lasso.fit( train_X, train_y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Kernel Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel_grid = {\n",
    "#     'alpha'  : [ 1 ],\n",
    "#     'kernel' : [ 'linear' ],\n",
    "#     'degree' : [ 1 ],\n",
    "#     'coef0'  : [ 0 ]\n",
    "# }\n",
    "\n",
    "# kridge = GridSearchCV( KernelRidge(), cv = 5, param_grid = kernel_grid, n_jobs = -1, scoring = 'neg_mean_squared_error', verbose = 1 )\n",
    "# kridge.fit( train_X, train_y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elastic_grid = {\n",
    "#     'alpha'        : [ 0.001 ],\n",
    "#     'l1_ratio'     : [ 0.5 ],\n",
    "#     'normalize'    : [ True ],\n",
    "#     'max_iter'     : [ 2500 ],\n",
    "#     'random_state' : [ 2 ]\n",
    "# }\n",
    "\n",
    "# elastic = GridSearchCV( ElasticNet(), cv = 5, param_grid = elastic_grid, n_jobs = -1, scoring = 'neg_mean_squared_error', verbose = 1 )\n",
    "# elastic.fit( train_X, train_y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm_grid = {\n",
    "#     'objective'        : [ 'regression' ],\n",
    "#     'n_estimators'     : [ 500 ],\n",
    "#     'learning_rate'    : [ 0.05 ],\n",
    "#     'num_leaves'       : [ 5 ],\n",
    "#     'max_bin'          : [ 60 ],\n",
    "#     'bagging_fraction' : [ 0.5 ],\n",
    "#     'feature_fraction' : [ 0.25 ],\n",
    "#     'colsample_bytree' : [ 0.5 ],\n",
    "#     'reg_alpha'        : [ 0 ],\n",
    "#     'reg_lambda'       : [ 0.25 ],\n",
    "#     'subsample'        : [ 0.5 ]\n",
    "# }\n",
    "\n",
    "# lgbm = GridSearchCV( lgb.LGBMRegressor(), cv = 5, param_grid = lgbm_grid, n_jobs = -1, scoring = 'neg_mean_squared_error', verbose = 1 )\n",
    "# lgbm.fit( train_X, train_y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Selected Model on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBRegressor\n",
    "# ==========\n",
    "xgbm_model = XGBRegressor(\n",
    "colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1\n",
    ")\n",
    "\n",
    "# GradientBoostingRegressor\n",
    "# ==================================================\n",
    "gbr_model = GradientBoostingRegressor( \n",
    "   n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5\n",
    ")\n",
    "\n",
    "# Lasso\n",
    "# ==================================================\n",
    "lasso_model = Lasso(\n",
    "alpha =0.0005, random_state=1\n",
    ") \n",
    "\n",
    "# KernelRidge\n",
    "# ==================================================\n",
    "kridge_model = KernelRidge(\n",
    "  alpha=0.6, kernel='polynomial', degree=2, coef0=2.5\n",
    ") \n",
    "\n",
    "# ElasticNet\n",
    "# ==================================================\n",
    "elastic_model = ElasticNet(\n",
    "alpha=0.0005, l1_ratio=.9, random_state=3\n",
    ") \n",
    "\n",
    "# LightGBM\n",
    "# ==================================================\n",
    "lgbm_model = lgb.LGBMRegressor(\n",
    "    objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-0feaca78bd8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                         meta_model  = lasso_model )\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mstacked_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mstacked_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mstacked_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "# Stacked CV Regressor\n",
    "stacked_model = StackingAveragedModels( base_models = ( elastic_model, gbr_model, kridge_model ),\n",
    "                                        meta_model  = lasso_model )\n",
    "\n",
    "stacked_model.fit( train_X.values, train_y.values )\n",
    "stacked_predict = np.expm1( stacked_model.predict( test_X.values ) )\n",
    "\n",
    "# LightGBM\n",
    "lgbm_model.fit( train_X, train_y )\n",
    "lgbm_predict = np.expm1( lgbm_model.predict( test_X ) )\n",
    "\n",
    "#XGBRegressor\n",
    "xgbm_model.fit( train_X, train_y )\n",
    "xgbm_predict = np.expm1( xgbm_model.predict( test_X ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble\n",
    "ensemble = stacked_predict * 0.70 +\\\n",
    "           lgbm_predict * 0.15 +\\\n",
    "           xgbm_predict * 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(\n",
    "    { 'Id'        : test_raw[ 'Id' ],\n",
    "      'SalePrice' : ensemble } \n",
    ")\n",
    "\n",
    "submission.to_csv( '.\\\\ames_housing_submit_3.csv', index = False )\n",
    "submission.head( 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\tId\tSalePrice\n",
    "# 2\t1461\t119993.52799010304\n",
    "# 3\t1462\t160505.5055045645\n",
    "# 4\t1463\t186796.66681037686\n",
    "# 5\t1464\t196605.93965842467"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
